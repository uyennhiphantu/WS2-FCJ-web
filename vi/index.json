[
{
	"uri": "/vi/",
	"title": "Bắt đầu với Amazon Athena",
	"tags": [],
	"description": "",
	"content": "Làm việc với Amazon Athena Trong bài lab này, chúng ta sẽ tìm hiểu về Athena Federation và User Defined Functions.\nAmazon Athena là dịch vụ interactive analytics, serverless, được xây dựng trên các open-source frameworks, hỗ trợ các định dạng file và open-table. Athena cung cấp một cách đơn giản, linh hoạt để phân tích hàng petabyte dữ liệu nơi nó tồn tại. Phân tích dữ liệu hoặc xây dựng ứng dụng từ data lake Amazon Simple Storage Service (S3) và 30 nguồn dữ liệu, bao gồm nguồn dữ liệu on-premises hoặc các hệ thống đám mây khác sử dụng SQL hoặc Python. Athena được xây dựng trên các công cụ Trino và Presto mã nguồn mở cũng như các Apache Spark frameworks mà không cần nỗ lực cung cấp hoặc cấu hình.\nNội dung Giới thiệu Các bước chuẩn bị Athena Federation User Defined Functions Dọn dẹp tài nguyên "
},
{
	"uri": "/vi/1-introduce/",
	"title": "Amazon Federation và User Defined Functions là gì?",
	"tags": [],
	"description": "",
	"content": "Ngày nay, những vấn đề mà doanh nghiệp đang gặp phải có thể bao gồm về hiệu suất truy vấn kém, khả năng mở rộng thấp, hoặc khả năng hiển thị dữ liệu không linh hoạt. Do đó, mục đích của workshop lần này nhằm cung cấp những kiến thức cơ bản của Amazon Athena để có thể giải quyết những nhu cầu cơ bản mà doanh nghiệp đang gặp phải. Workshop này không bắt buộc bạn phải có kiến thức về Amazon Athena, nhưng nếu có thì nó là một lợi thế.\nTiếp nối với các khái niệm cơ bản và thực hành về Amazon Athena. Chúng ta sẽ tiếp nối với Athena Federation và User Defined Functions. Athena Federation và User Defined Functions (UDFs) đều là các công cụ quan trọng trong việc giải quyết các thách thức về xử lý và phân tích dữ liệu mà các doanh nghiệp thường gặp phải ngày nay.\nAthena Federation cho phép tích hợp dữ liệu từ nhiều nguồn khác nhau, mở rộng khả năng truy cập và sử dụng dữ liệu từ các hệ thống khác nhau. Điều này giải quyết vấn đề về khả năng mở rộng thấp và khó khăn trong việc truy cập vào dữ liệu từ các nguồn không đồng nhất, giúp doanh nghiệp hiểu rõ hơn về toàn bộ hệ thống thông tin của mình.\nTrong khi đó, User Defined Functions (UDFs) cho phép tạo ra các hàm tùy chỉnh, giúp doanh nghiệp thực hiện các xử lý dữ liệu đặc thù và phức tạp. Các UDFs cung cấp sức mạnh và linh hoạt cho việc tối ưu hóa truy vấn và phân tích dữ liệu, giúp doanh nghiệp tìm ra thông tin quan trọng và đưa ra quyết định hiệu quả hơn.\nNhờ vào Athena Federation và User Defined Functions, các doanh nghiệp có thể nhanh chóng truy cập và sử dụng dữ liệu từ nhiều nguồn khác nhau, cũng như tối ưu hóa quá trình xử lý và phân tích dữ liệu, giúp họ có cái nhìn toàn diện và chi tiết hơn về hoạt động kinh doanh, từ đó đưa ra những quyết định thông minh và hiệu quả.\n"
},
{
	"uri": "/vi/4-user-defined/4.1-cloud9/",
	"title": "Cloud9 IDE",
	"tags": [],
	"description": "",
	"content": "Trong bài lab này, chúng ta sẽ sử dụng AWS Cloud9 IDE. Cloud9 IDE environment phải có sẵn như một phần của cloud formation stack đã được chạy trước đó.\nSử dụng tìm kiếm dịch vụ và nhập cloud9 như hình bên dưới. Mở Open IDE Sau khi Cloud9 IDE khởi chạy, bạn sẽ thấy một màn hình như thế này: Cloud9 IDE đi kèm với dung lượng ổ đĩa 10 GB mặc định, dung lượng này có thể lấp đầy nhanh chóng khi chúng ta thiết lập môi trường phát triển. Chạy lệnh bên dưới để lấy tập lệnh thay đổi kích thước rồi chạy nó để tăng kích thước ổ đĩa lên 20GB. curl https://aws-data-analytics-workshops.s3.amazonaws.com/athena-workshop/scripts/cloud9\\_resize.sh \u0026gt; cloud9\\_resize.sh ​Chạy tập lệnh bằng cách đưa ra lệnh sau trên thiết bị đầu cuối cloud9. Điều này sẽ thay đổi kích thước đĩa thành 20GB.\nsh cloud9\\_resize.sh 20 Kiểm tra dung lượng trống trên đĩa bằng lệnh bên dưới.\ndf -h Bạn sẽ thấy như hình dưới đây:\n"
},
{
	"uri": "/vi/3-federation/3.1-tpch/",
	"title": "TPCH Database &amp; Tables",
	"tags": [],
	"description": "",
	"content": "Thử nghiệm dữ liệu \u0026amp; người dùng Để thể hiện khả năng federation của Athena, một tập dữ liệu mẫu đang được sử dụng trong workshop này cùng với các bảng mẫu và nguồn dữ liệu mẫu.\nHãy cùng xem qua các thử nghiệm datasets \u0026amp; data sources sau:\nTPCH Database \u0026amp; Tables Dữ liệu TPCH, một tập dữ liệu công cộng, sẽ được sử dụng cho buổi workshop này. Dataset này là một chuẩn đoán hỗ trợ quyết định. Nó bao gồm một loạt các truy vấn linh hoạt theo hướng kinh doanh và các sửa đổi dữ liệu đồng thời. Các truy vấn và dữ liệu trong cơ sở dữ liệu đã được lựa chọn để có tính phổ quát trong ngành công nghiệp. Kiểm chuẩn (Benchmark) này mô tả các hệ thống hỗ trợ quyết định xem xét các khối lượng dữ liệu lớn, thực hiện các truy vấn với độ phức tạp cao và cung cấp câu trả lời cho những câu hỏi kinh doanh quan trọng. TPCH bao gồm tám bảng riêng biệt (Base Tables). Mối quan hệ giữa các cột trong các bảng này được minh họa trong biểu đồ sau: Trong workshop này, chúng ta sẽ tập trung vào các bảng sau từ cơ sở dữ liệu TPC:\ncustomer supplier orders part partsupp lineitem nation Toàn bộ từ điển TPCH data có sẵn ở đây: chèn link "
},
{
	"uri": "/vi/2-prepare/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Labs - Federated Queries, User Defined Functions CloudFormation stack sẽ mất khoảng 20-30 phút để hoàn thành.\nLaunch stack CloudFormation stack sẽ mất khoảng 20-30 phút để hoàn thành.\nCloudFormation stack sẽ tạo một cơ sở dữ liệu TPC mẫu chạy trên Amazon RDS, Amazon EMR Cluster với HBase, Amazon Elasticache Redis, Amazon DynamoDB, Glue Database và tables, S3 Bucket, S3 VPC Endpoint, Glue VPC Endpoint, Athena Named Queries, Cloud9 IDE, phiên bản SageMaker Notebook và các tài nguyên IAM khác. Kiểm tra bảng điều khiển CloudFormation và đợi trạng thái CREATE_COMPLETE như hiển thị bên dưới: Khi bạn thấy CloudFormation đã hoàn tất, hãy truy cập EMR console và kiểm tra trạng thái của các bước. Đợi nếu nó ở trạng thái Running để nó hoàn thành.\nĐể khởi chạy EMR, hãy truy cập Dịch vụ và nhập EMR như hiển thị ở đây: Sau khi khởi chạy EMR, bạn sẽ thấy nó được hiển thị như thế này: Click vào EMR-Hbase-Cluster.\nSau đó click Steps như hình bên dưới để kiểm tra trạng thái của bước đó. Đợi cho đến khi nó hiển thị hoàn thành. Sau khi quá trình tạo stack hoàn tất, tài khoản AWS của bạn sẽ có tất cả tài nguyên cần thiết để chạy workshop này. Ghi lại tên S3 lake bucket name, subnets, WorkshopSecurityGroup, EMRSecurityGroup, HbaseConnectionString, RDSConnectionString từ tab đầu ra và chuyển sang chương tiếp theo để chạy lab khác. ​\n"
},
{
	"uri": "/vi/3-federation/3.2-data-sources/",
	"title": "Data Sources",
	"tags": [],
	"description": "",
	"content": "Giả định một công ty thương mại điện tử có kiến ​​trúc sử dụng như sau:\nXử lý bản ghi Lineitems được lưu trữ trong HBase trên EMR Sử dụng Redis để lưu trữ thông tin về quốc gia và các đơn hàng hoạt động để hệ thống xử lý có thể truy cập nhanh chóng vào chúng Aurora với động cơ MySQL để lưu trữ dữ liệu về Orders, Customer và Suppliers như địa chỉ email, địa chỉ giao hàng, vv. Sử dụng DynamoDB để lưu trữ dữ liệu về các part và partsupp data để đạt hiệu suất cao. Đối với workshop này, chúng ta sẽ tập trung vào các nguồn dữ liệu sau:\nHBase trên EMR Hệ thống lưu trữ dữ liệu tối ưu Tỷ lệ giao dịch cao Độ bền lâu dài Aurora với MySQL engine Bản sao đọc có thể mở rộng Có khả năng mở rộng đọc bản sao Yêu cầu tỷ lệ ghi thấp Bảo mật cao Amazon DynamoDB Có khả năng mở rộng cao Hiệu suất cao Linh hoạt Redis trên ElastiCache Đọc và ghi với độ trễ thấp Ít thông tin ngữ cảnh Trong bộ nhớ với khả năng tái tạo "
},
{
	"uri": "/vi/3-federation/",
	"title": "Athena Federation",
	"tags": [],
	"description": "",
	"content": "Truy vấn dữ liệu mọi nơi Chạy các federated queries đối với databases, data warehouses, object stores, và non-relational data stores. Truy vấn Federated SQL cho phép chúng ta truy vấn dữ liệu được thiết lập từ bất kỳ nơi nào có dữ liệu đó. Chúng ta có thể sử dụng dữ liệu SQL thường dùng để JOIN trên nhiều nguồn dữ liệu để phân tích nhanh chóng, và lưu trữ kết quả trong Amazon S3 để sử dụng sau này. Truy vấn Athena federated cũng đưa ra truy vấn Federation SDK mới cho phép chúng ta viết trình kết nối nguồn dữ liệu của riêng mình để truy vấn các kho dữ liệu tùy chỉnh.\nFederated Queries Labs! Amazon Athena sử dụng các nguồn dữ liệu chạy trên AWS Lambda để thực hiện các truy vấn federated. Một trình kết nối dữ liệu là một đoạn mã có thể chuyển giữa nguồn dữ liệu mục tiêu của chúng ta và Athena. Bạn có thể coi trình kết nối dữ liệu như một phần mở rộng của công cụ truy vấn của Athena. Khi một truy vấn được gửi đến một nguồn dữ liệu, Athena gọi trình kết nối dữ liệu tương ứng để xác định các phần của các bảng cần đọc, quản lý tính song song và đẩy các điều kiện lọc xuống. Dựa trên việc người dùng gửi truy vấn, các trình kết nối dữ liệu có thể cung cấp hoặc hạn chế truy cập vào các phần dữ liệu cụ thể. Bằng cách thực hiện các bài tập từ những bài thực hành này, chúng ta sẽ biết cách sử dụng các trình kết nối dữ liệu Amazon Athena khác nhau để chạy các truy vấn federated. Kinh nghiệm với Amazon Athena sẽ hữu ích nhưng không bắt buộc. Hãy làm theo các bước sau một cách tuần tự để hoàn thành các bài thực hành sau:\nNội dung 3.1 TPCH Database \u0026amp; Tables 3.2 Data Sources 3.3 Prerequisites 3.4 DynamoDB Connector 3.5 Aurora Connector 3.6 HBase Connector 3.7 Redis Connector 3.8 Run Federated Queries 3.9 Visualize with QuickSight "
},
{
	"uri": "/vi/3-federation/3.3-prerequisites/",
	"title": "Điều kiện tiên quyết",
	"tags": [],
	"description": "",
	"content": "Self Paced Labs Nếu bạn đang tự mình thực hành các bài labs này, hãy đảm bảo rằng bạn đã triển khai Cloudformation stack cho bài Labs - Federated Queries, User Defined Functions, Custom Connector \u0026amp; Machine Learning\nĐi tới Cloudformation và tìm ngăn xếp có mô tả Athena Federation Workshop.\nClick vào tên Stack như hình bên dưới rồi click vào Outputs ​ Bạn sẽ thấy kết quả outputs như dưới đây. Sao chép kết quả outputs vào sổ ghi chú hoặc trình soạn thảo văn bản để tham khảo sau hoặc giữ tab thông tin đám mây luôn mở. "
},
{
	"uri": "/vi/4-user-defined/4.2-setting-/",
	"title": "Cài đặt Development Environment",
	"tags": [],
	"description": "",
	"content": "Sao chép SDK và chuẩn bị môi trường phát triển của bạn. Trước khi bắt đầu, hãy đảm bảo rằng git đã được cài đặt trên hệ thống của bạn bằng lệnh sau.\nsudo yum install git -y Cài đặt AWS Query Federation SDK Nhập thông tin sau vào dòng lệnh để sao chép kho SDK. Kho lưu trữ này bao gồm SDK, ví dụ và bộ trình kết nối nguồn dữ liệu. Để biết thêm thông tin về trình kết nối nguồn dữ liệu, hãy xem Using Amazon Athena Federated Query.\ngit clone https://github.com/awslabs/aws-athena-query-federation.git Install prerequisites Nếu bạn đang làm việc trên máy phát triển đã cài đặt sẵn Apache Maven, AWS CLI và công cụ xây dựng AWS Serverless Application Model, bạn có thể bỏ qua bước này. Từ thư mục gốc của thư mục aws-athena-query-federation mà bạn đã tạo khi sao chép, hãy chạy tập lệnh prepare_dev_env.sh để chuẩn bị cho môi trường phát triển của bạn.\ncd aws-athena-query-federation\rsudo chown ec2-user:ec2-user ~/.profile\rcurl https://aws-data-analytics-workshops.s3.amazonaws.com/athena-workshop/scripts/prepare_dev_env.sh \u0026gt; tools/prepare_dev_env.sh\rcurl https://aws-data-analytics-workshops.s3.amazonaws.com/athena-workshop/scripts/publish.sh \u0026gt; tools/publish.sh\r./tools/prepare_dev_env.sh Cập nhật shell của bạn để lấy nguồn các biến mới được tạo bởi quá trình cài đặt hoặc bởi khởi động lại phiên cuối của bạn.\nsource ~/.profile "
},
{
	"uri": "/vi/3-federation/3.4dynamodb-connector/",
	"title": "DynamoDB Connector",
	"tags": [],
	"description": "",
	"content": "Để biết thông tin chi tiết về Amazon Athena DynamoDB Connector, hãy tham khảo tại đây.\nBạn có thể cài đặt Athena DynamoDB Connector bằng một trong hai cách được nêu bên dưới. ​\nCài đặt Athena DynamoDB Connector bằng Athena Console Trong bảng điều khiển Athena, nhấp vào biểu tượng bánh hamburger (3 đường ngang) ở góc trên cùng bên trái và chọn \u0026ldquo;Data sources\u0026rdquo;. Trên trang Data sources, click Connect data source Chọn nguồn dữ liệu là DynamoDB mà bạn muốn kết nối, như trong ảnh chụp màn hình sau và click Next Trong Chi tiết nguồn dữ liệu: đối với Data source name, hãy nhập dynamo_db và trong hàm Lambda, click \u0026lsquo;Create Lambda function\u0026rsquo; để mở một tab/cửa sổ mới tới AWS Lambda Console. Điền vào các fields cài đặt ứng dụng theo ảnh chụp nhanh bên dưới, click \u0026ldquo;I acknowledge that this app creates custom IAM roles\u0026rdquo; và click vào deploy: Đợi chức năng triển khai. Quay lại cửa sổ Athena, click nút làm mới bên cạnh Lambda function. Chọn Lambda function mới được triển khai và nhấp vào \u0026lsquo;Next\u0026rsquo; Xem lại thông tin và nhấp vào \u0026lsquo;Create data source\u0026rsquo; Click vào Data Sources và xác minh rằng data source mới hiển thị Điều hướng trở lại query editor, chọn nguồn dữ liệu mới và xem xét liệu nó có hiển thị cơ sở dữ liệu hay không. Connnector đã được triển khai và sẵn sàng để sử dụng. Bạn có thể gọi connector trong truy vấn của mình là \u0026ldquo;lambda:dynamo\u0026rdquo; hoặc dynamo_db.dynamo Tùy chọn 2: Cài đặt Athena DynamoDB Connector bằng Serverless Application Repository Để cài đặt Athena DynamoDB Connector, hãy tìm kiếm \u0026ldquo;Serverless Application Repository\u0026rdquo; trong tài khoản aws của bạn và nhấp vào \u0026ldquo;Available applications\u0026rdquo;: Đảm bảo đánh dấu \u0026ldquo;Show apps that create custom IAM roles or resource policies\u0026rdquo;. Tìm kiếm \u0026ldquo;AthenaDynamoDBConnector\u0026rdquo; và chọn thẻ có AWS verified author, click vào đó: ​ ​Đối với Athena DynamoDB Connector này, có một số trường chúng ta cần hoàn thành: Click vào \u0026ldquo;I acknowledge that this app creates custom IAM roles\u0026rdquo; và click vào deploy: ​ Thao tác này sẽ triển khai Athena DynamoDB connector và bạn có thể gọi hàm lambda này trong truy vấn của mình là \u0026ldquo;lambda:dynamo\u0026rdquo;\n"
},
{
	"uri": "/vi/4-user-defined/4.3-udf-code-/",
	"title": "UDF Code và Publish",
	"tags": [],
	"description": "",
	"content": " Mở dự án Trong IDE Cloud9 ở phía bên trái, hãy mở rộng dự án aws-athena-query-federation và điều hướng đến tệp AthenaUDFHandler.java. Nhấp đúp chuột vào tệp và nó sẽ mở ra để chỉnh sửa như hiển thị ở đây: 2. Thêm UDF Function Bây giờ chúng ta sẽ thêm mã UDF cho hàm Redact String để sắp xếp lại một chuỗi để chỉ hiển thị 4 ký tự cuối cùng. Chức năng UDF này có thể được sử dụng để che Credit Card Information, SSN hoặc các thông tin nhạy cảm khác như Tên khách hàng, Số điện thoại, Địa chỉ, v.v. Hàm này lấy một chuỗi làm đầu vào và trả về một chuỗi đã được xử lý lại để chỉ hiển thị 4 ký tự cuối cùng, ví dụ: xxxx1234. Hàm UDF lấy tên cột làm đầu vào từ nguồn dữ liệu đang được sử dụng như một phần của truy vấn, xử lý tên cột đó bằng mã hàm lambda rồi trả về dữ liệu cho Athena.\n/** Redact a string to show only the last 4 characters\r* * * * @param input the string to redact\r* @return redacted string\r*/\rpublic String redact(String input)\r{\rString redactedString = new StringBuilder(input).replace(0, input.length() - 4, new String(new char[input.length() - 4]).replace(\u0026#34;\\0\u0026#34;, \u0026#34;x\u0026#34;)).toString(); return redactedString;\r} Bạn có thể sao chép đoạn mã ở dòng 61 trong AthenaUDFHandler.java hoặc bạn có thể lấy mã UDF đã sửa đổi bằng cách đưa ra lệnh sau:\ncurl https://aws-data-analytics-workshops.s3.amazonaws.com/athena-workshop/scripts/AthenaUDFHandler.java \u0026gt; athena-udfs/src/main/java/com/amazonaws/athena/connectors/udfs/AthenaUDFHandler.java Sau khi sao chép tệp, bạn có thể mở tệp đó trong Cloud9 IDE để xem nội dung của tệp.\nBuild the JAR File Lưu tệp và chạy mvn clean install để xây dựng dự án của bạn. Sau khi xây dựng thành công, một tệp JAR sẽ được tạo trong thư mục đích của dự án của bạn có tên ArtifactId-version.jar, trong đó ArtifactId là tên bạn đã cung cấp trong dự án Maven, ví dụ: athena-udfs. cd ~/environment/aws-athena-query-federation/athena-udfs/ mvn install -DskipTests "
},
{
	"uri": "/vi/4-user-defined/4.4-udf-connector/",
	"title": "UDF Connector Setup",
	"tags": [],
	"description": "",
	"content": "Bây giờ UDF Connector code đã được xuất bản, chúng ta có thể cài đặt trình kết nối UDF để sử dụng với Athena:\nNhấp vào ứng dụng AthenaUserDefinedFunctions trong ứng dụng Privateapplications từ Serverless Application Repository. Thực hiện theo các hướng dẫn được liệt kê bên dưới để vào Cài đặt ứng dụng:\nApplication Name: Để nguyên tên mặc định - AthenaUserDefinedFunctions. SecretNameorPrefix: Nhập tên bí mật nếu bạn đã lưu trong Secrets Manager, nếu không hãy nhập database-*. LambdaFunctionName: Nhập customudf Nó sẽ giống như thế này: Bấm vào Deploy để triển khai connector.\nChuyển sang chương tiếp theo khi UDF được triển khai thành công. Nó sẽ giống như thế này: "
},
{
	"uri": "/vi/4-user-defined/",
	"title": "User Defined Functions",
	"tags": [],
	"description": "",
	"content": "Amazon Athena hiện đã hỗ trợ các user-defined functions (UDFs), một tính năng cho phép khách hàng viết các functions custom scalar và gọi chúng trong các truy vấn SQL. Trong khi Athena cung cấp các hàm tích hợp sẵn (built-in functions), UDFs cho phép khách hàng thực hiện xử lý tuỳ chỉnh như nén và giải nén dữ liệu, che giấu thông tin nhạy cảm hoặc áp dụng decryption tuỳ chỉnh. Khách hàng có thể viết các UDF của họ bằng Java sử dụng Athena Query Federation SDK. Khi một UDF được sử dụng trong một truy vấn SQL gửi đến Athena, nó được gọi và thực thi trên AWS Lambda. UDFs có thể được sử dụng trong cả các mệnh đề SELECT và FILTER của một truy vấn SQL. Người dùng có thể gọi nhiều UDF trong cùng một truy vấn.\nCác lab này bao gồm các chức năng cơ bản của Athena UDF, viết UDF của riêng bạn, xây dựng và xuất bản UDF của bạn đến Serverless Application Repository, cấu hình ứng dụng kết nối UDF sau đó sử dụng UDF trong các truy vấn Athena.\nMột số trường hợp sử dụng như che giấu thông tin nhạy cảm, thông tin PII, Credit Card, SSN, v.v. có thể được triển khai như một UDF. Thêm tài liệu về việc truy vấn Athena UDF có thể được tìm thấy tại đây: Truy vấn UDF\nThực hiện theo từng bước một để hoàn thành các bài labs này:\n4.1 Cloud9 IDE 4.2 Setting Development Environment 4.3 UDF Code and Publish 4.4 UDF Connector Setup 4.5 Querying with UDF "
},
{
	"uri": "/vi/5-cleanup/",
	"title": "Dọn dẹp tài nguyên  ",
	"tags": [],
	"description": "",
	"content": "Chúng ta sẽ tiến hành các bước sau để xóa các tài nguyên chúng ta đã tạo trong bài thực hành này.\nXóa Cloudformation Truy cập giao diện quản trị dịch vụ Cloudformation. Sau đó chúng ta sẽ thấy mục stack đã tạo athena-federation-workshop Chọn athena-federation-workshop sau đó nhấn Delete Vậy là chúng ta đã hoàn thành xong bài Workshop về Athena Federation và User Defined Functions "
},
{
	"uri": "/vi/3-federation/3.5-aurora-connector/",
	"title": "Aurora Connector",
	"tags": [],
	"description": "",
	"content": "Với Athena Jdbc Connector, các cơ sở dữ liệu sau đã được hỗ trợ:\nMySQL PostgreSQL Redshift Để biết thông tin chi tiết về Amazon Athena Jdbc Connector, hãy tham khảo tại đây.\nAthena MySql Connector có thể được cài đặt như được nêu bên dưới.\nCài đặt Athena MySql Connector bằng Athena Console Trong Athena console, nhấp vào biểu tượng bánh hamburger (3 đường ngang) ở góc trên cùng bên trái và chọn \u0026ldquo;Data sources\u0026rdquo;. Ở trang Data Sources, click Connect data source Chọn data source là Mysql mà bạn muốn kết nối, như trong ảnh chụp màn hình sau và click Next Trong phần Data source detail: đối với Data source name, nhập mysql. Lambda function đã được triển khai như một phần của workshop này. Click Select or enter a Lambda function. Chọn mysql và click \u0026lsquo;Next\u0026rsquo; Xem lại thông tin và click \u0026lsquo;Create data source\u0026rsquo; ​ Click vào Data Source và xác minh rằng new Data Source hiển thị Click vào mysql datasource và sau đó chọn vào liên kết mysql lambda function như dưới đây: Điều hướng đến Configuration tab và chọn Environment variables rồi chọn Edit. Thêm một biến new environment variable với tên mysql_connection_string và sao chép giá trị của biến mặc định sang biến mới này (database connection string). Lưu ý: The environment variable name là tên của data source với suffix _connection_string, do đó trong trường hợp này là mysql_connection_string. Điều hướng trở lại query editor, chọn nguồn dữ liệu mới và xem xét liệu nó có hiển thị cơ sở dữ liệu hay không. The connector đã được triển khai và sẵn sàng để sử dụng. Bạn có thể gọi connector trong truy vấn của mình là \u0026ldquo;lambda:mysql\u0026rdquo; hoặc mysql.sale "
},
{
	"uri": "/vi/4-user-defined/4.5-udf-querying/",
	"title": "Truy vấn bằng UDF",
	"tags": [],
	"description": "",
	"content": "Bây giờ UDF Connector code đã được triển khai, chúng ta có thể chạy các truy vấn sử dụng UDF:\nTìm kiếm Athena trong Services như hiển thị bên dưới: Đảm bảo bạn đang ở trong Workgroup: V2EngineWorkGroup. Nếu không nhấn vào Workgroup rồi chọn V2EngineWorkGroup và click Switch Workgroup Nhấp vào Saved Queries và chọn RedactUdfCustomerAddress Bạn sẽ thấy nó như thế này: Để tìm hiểu thêm về cú pháp UDF bấm vào đây: UDF Query Syntax Click Run query. Khi truy vấn thực hiện thành công, bạn sẽ thấy kết quả như thế này: "
},
{
	"uri": "/vi/3-federation/3.6-hbase/",
	"title": "HBase Connector",
	"tags": [],
	"description": "",
	"content": " Để biết thông tin chi tiết về Amazon Athena HBase Connector, hãy tham khảo tại đây.\nAthena HBase Connector có thể được cài đặt như được nêu dưới đây.\nCài đặt Athena HBase Connector bằng Athena Console Trong bảng điều khiển Athena, nhấp vào biểu tượng bánh hamburger (3 đường ngang) ở góc trên cùng bên trái và chọn \u0026ldquo;Data sources\u0026rdquo;. Trên trang Data Sources, nhấp vào Connect data source Chọn data source là Apache HBase mà bạn muốn kết nối, như trong ảnh chụp màn hình sau và nhấp vào Next Trong phần chi tiết Data source: phần Data source name, nhập hbase_db. Lambda function đã được triển khai như một phần của workshop này. Click vào Select or enter a Lambda function. Chọn hbase và nhấp vào \u0026lsquo;Tiếp theo\u0026rsquo; Xem lại thông tin và nhấp vào \u0026lsquo;Create data source\u0026rsquo; Click vào Data Sources và xác minh rằng new data source hiển thị Điều hướng trở lại query editor và chọn nguồn dữ liệu mới và xem xét liệu nó có hiển thị cơ sở dữ liệu hay không. Connector đã được triển khai và sẵn sàng để sử dụng. Bạn có thể xem xét connector trong truy vấn của mình dưới dạng \u0026ldquo;lambda:hbase\u0026rdquo; hoặc hbase_db.hbase. "
},
{
	"uri": "/vi/3-federation/3.7-redis-connector/",
	"title": "Redis Connector",
	"tags": [],
	"description": "",
	"content": " Để biết thông tin chi tiết về Amazon Athena Redis Connector, hãy tham khảo tại đây.\nAthena Redis Connector có thể được cài đặt như được nêu bên dưới.\nCài đặt Athena Redis Connector bằng Bảng điều khiển Athena Trong Athena Console, nhấp vào biểu tượng bánh hamburger (3 đường ngang) ở góc trên cùng bên trái và chọn \u0026ldquo;Data sources\u0026rdquo;. Ở trang Data Sources, click mục Connect data source Chọn data source là Redis mà bạn muốn kết nối, như trong ảnh chụp màn hình sau và nhấp vào Next Trong phần Data source details: đối với Data source name, hãy nhập redis. The lambda function đã được triển khai như một phần của workshop này. Click vào Select hoặc Lambda function. Chọn redis và nhấp vào \u0026lsquo;Next\u0026rsquo; Xem lại thông tin và nhấp vào \u0026lsquo;Create data source\u0026rsquo; Click vào Data Sources và xác minh rằng new data source hiển thị Điều hướng trở lại query editor và chọn nguồn dữ liệu mới và xem xét liệu nó có hiển thị cơ sở dữ liệu hay không. Connector đã được triển khai và sẵn sàng để sử dụng. Bạn có thể xem xét connector trong truy vấn của mình dưới dạng \u0026ldquo;lambda:redis\u0026rdquo; hoặc redis.redis. Redis Database và Tables with Glue Data Catalog Vì Redis không có schema riêng nên Redis Connector không thể suy ra các cột hoặc kiểu dữ liệu từ Redis. Trình kết nối Redis cần thiết lập cơ sở dữ liệu Glue và các bảng để có thể liên kết dữ liệu với lược đồ. Cloudformation template tạo cơ sở dữ liệu Redis và các bảng cần thiết trong Glue Catalog. Mở Glue như hình ở đây: Bạn sẽ thấy cơ sở dữ liệu redis sau trong Glue Databases: Nhấp vào cơ sở dữ liệu redis để xem các thuộc tính cơ sở dữ liệu: redis to view các bảng: Click bảng Nation để xem schema và thuộc tính của bảng: Click vào Active Orders đang hoạt động để xem schema và thuộc tính của bảng: Bây giờ bạn đã thiết lập xong tất cả connectors, hãy chuyển sang chương tiếp theo để chạy các federated queries. ​\n"
},
{
	"uri": "/vi/3-federation/3.8-run-federated/",
	"title": "Run Federated Queries ",
	"tags": [],
	"description": "",
	"content": " Bây giờ, Connectors đã được triển khai, chúng ta có thể chạy các truy vấn Athena mà nó sử dụng connectors:\nĐi tới bảng điều khiển Athena: https://console.aws.amazon.com/athena/. Click vào Bắt đầu.\nĐảm bảo bạn đang ở trong Workgroup: V2EngineWorkGroup. Để sử dụng tính năng federated queries và các tính năng khác như features do User Defined Function (UDFs) and ML Inference, các truy vấn cần chạy trên công cụ Athena phiên bản 2. V2EngineWorkGroup được cấu hình với v2 engine. Nếu bạn không thuộc workgroup này, hãy click vào Workgroup và chọn V2EngineWorkGroup ​ Click vào Saved Queries và Select Sources Bạn sẽ thấy các truy vấn như thế này: Các truy vấn này kiểm tra chức năng Athena Connector của bạn cho từng data source và bạn có thể đảm bảo rằng bạn có thể trích xuất dữ liệu từ từng data source trước khi chạy các truy vấn phức tạp hơn, liên quan đến các nguồn dữ liệu khác nhau. Select truy vấn đầu tiên và nhấp vào click Run query. Khi truy vấn thực hiện thành công, bạn sẽ thấy kết quả như thế này: Bây giờ bạn có thể quay lại Saved Queries và thử các truy vấn sau:\nFetchActiveOrderInfo\nProfitBySupplierNationByYr\nOrdersRevenueDateAndShipPrio\nSuppliersWhoKeptOrdersWaiting\nShippedLineitemsPricingReport**\n"
},
{
	"uri": "/vi/3-federation/3.9-visual/",
	"title": "Visualize with QuickSight",
	"tags": [],
	"description": "",
	"content": " Trong bài labs này, chúng ta sẽ chứng minh các khả năng của Athena federation bằng cách sử dụng data source connectors, sau đó tạo QuickSight dashboards bằng cách sử dụng data source catalog.\nThiết lập QuickSight để sử dụng connectors Từ AWS services console, hãy điều hướng đến QuickSight (https://quicksight.aws.amazon.com/sn/start ). Click vào Amazon QuickSight và nó sẽ tải một vài mẫu. Bạn có thể đóng cửa sổ thông báo tính năng mới. Sau khi bạn đăng nhập vào QuickSight, hãy chọn Manage QuickSight trong tài khoản của bạn. Trong ngăn điều hướng, chọn Security \u0026amp; permissions. Trong QuickSight access to AWS services, chọn Manage. Một trang xuất hiện để cho phép bạn truy cập QuickSight vào các dịch vụ AWS. Chọn Athena từ các tùy chọn. Trong cửa sổ bật lên, chọn Next. Trên tab Lambda, chọn các Lambda functions tương ứng với các connectors mà Athena federated queries sử dụng. Chọn các Lambda functions cho trình kết nối dynamo, hbase, mysql và redis rồi chọn Finish. Trên QuickSight console, chọn New analysis. Chọn New dataset. Chọn Athena cho Datasets, nhập Athena-federation làm Data source name. Đối với Athena workgroup, chọn primary. Chọn Create data source. Đối với Catelog, hãy chọn catelog được tạo cho các Athena federated connectors (dynamo, redis, hbase, mysql) Đối với bài labs này, hãy chọn dynamo catalog để federation với Athena DynamoDB connector. Chọn Edit/Preview trước dữ liệu để xem dữ liệu. Để kết nối với Athena data source khác, chọn Add data và chọn Data Source Chọn Athena-federation và nhấp vào Select. Chọn danh mục dynamo_db và bảng partsupp rồi nhấn Select ​17. Chọn liên kết nối giữa hai tập dữ liệu và chọn cấu hình nối thích hợp. Chọn Apply. Xem joined data như dưới đây: 18.Chọn Publish \u0026amp; Visualize để bắt đầu sử dụng dữ liệu này nhằm tạo trực quan hóa trong QuickSight Chạy truy vấn trong QuickSight Chúng ta sử dụng custom SQL trong QuickSight để chạy một truy vấn phức tạp với Athena federated data sources.\nTrên QuickSight console, chọn New analysis. Chọn New dataset Đối với Datasets, chọn Athena. Đối với Data source name, hãy nhập Athena-federation. Đối với Athena workgroup, chọn primary. Chọn Create data source. Chọn Use custom SQL. Nhập truy vấn cho ProfitBySupplierNation. ​ SELECT nation,\ro_year,\rsum(amount) AS sum_profit\rFROM (SELECT n_name AS nation,\ryear(cast(o_orderdate AS date)) AS o_year,\r\u0026#34;line:l_extendedprice\u0026#34; * (1 - \u0026#34;line:l_discount\u0026#34;) - cast(ps_supplycost AS double) * \u0026#34;line:l_quantity\u0026#34; AS amount\rFROM \u0026#34;lambda:dynamo\u0026#34;.default.part, \u0026#34;lambda:mysql\u0026#34;.sales.supplier, \u0026#34;lambda:hbase\u0026#34;.default.lineitem, \u0026#34;lambda:dynamo\u0026#34;.default.partsupp, \u0026#34;lambda:mysql\u0026#34;.sales.orders, \u0026#34;lambda:redis\u0026#34;.redis.nation\rWHERE s_suppkey = \u0026#34;line:l_suppkey\u0026#34;\rAND ps_suppkey = \u0026#34;line:l_suppkey\u0026#34;\rAND ps_partkey = \u0026#34;line:l_partkey\u0026#34;\rAND p_partkey = \u0026#34;line:l_partkey\u0026#34;\rAND o_orderkey = \u0026#34;line:l_orderkey\u0026#34;\rAND s_nationkey = cast(Regexp_extract(_key_, \u0026#39;.*-(.*)\u0026#39;, 1) AS int)\rAND p_name LIKE \u0026#39;%green%\u0026#39; ) AS profit\rGROUP BY nation, o_year\rORDER BY nation, o_year desc; Chọn Edit/Preview data. Trong Query mode, chọn SPICE.\nChọn Apply rồi chọn Publish \u0026amp; visualize. Trên trang Visualize, trong danh sách Trường, chọn nation và sum_profit. QuickSight tự động chọn loại hiển thị tốt nhất dựa trên các trường đã chọn. Bạn có thể thay đổi loại hình ảnh dựa trên yêu cầu của bạn. ​ Sau khi phân tích đã sẵn sàng, hãy chọn Share để tạo bảng thông tin và chia sẻ nó trong tổ chức của bạn.\nOptional Dưới đây là các truy vấn đã lưu khác có thể được sử dụng để tạo Athena datasets: FetchActiveOrderInfo\nSELECT *\rFROM \u0026#34;lambda:redis\u0026#34;.redis.active_orders ao\rLEFT JOIN \u0026#34;lambda:mysql\u0026#34;.sales.orders o\rON ao.orderkey = o_orderkey\rLEFT JOIN \u0026#34;lambda:mysql\u0026#34;.sales.customer c\rON o_custkey = c_custkey\rLEFT JOIN \u0026#34;lambda:hbase\u0026#34;.default.lineitem l\rON \u0026#34;line:l_orderkey\u0026#34; = o_orderkey\rLEFT JOIN \u0026#34;lambda:dynamo\u0026#34;.default.part p\rON \u0026#34;line:l_partkey\u0026#34; = p.p_partkey\rLEFT JOIN \u0026#34;lambda:dynamo\u0026#34;.default.partsupp ps\rON p.p_partkey = ps.ps_partkey\rLEFT JOIN \u0026#34;lambda:mysql\u0026#34;.sales.supplier s\rON ps_suppkey = s_suppkey; OrdersRevenueDateAndShipPrio\nSELECT \u0026#34;line:l_orderkey\u0026#34;,\rsum(\u0026#34;line:l_extendedprice\u0026#34;*(1-\u0026#34;line:l_discount\u0026#34;)) AS revenue,\ro_orderdate,\ro_shippriority\rFROM \u0026#34;lambda:mysql\u0026#34;.sales.customer c, \u0026#34;lambda:mysql\u0026#34;.sales.orders o, \u0026#34;lambda:hbase\u0026#34;.default.lineitem l\rWHERE c_mktsegment = \u0026#39;AUTOMOBILE\u0026#39;\rAND c_custkey = o_custkey\rAND \u0026#34;line:l_orderkey\u0026#34; = o_orderkey\rGROUP BY \u0026#34;line:l_orderkey\u0026#34;, o_orderdate, o_shippriority\rORDER BY revenue desc, o_orderdate\rlimit 10; SuppliersWhoKeptOrdersWaiting\nselect\rs_name, count(*) as numwait\rfrom\r\u0026#34;lambda:mysql\u0026#34;.sales.supplier,\r\u0026#34;lambda:hbase\u0026#34;.default.lineitem l1,\r\u0026#34;lambda:mysql\u0026#34;.sales.orders\rwhere\rs_suppkey = \u0026#34;line:l_suppkey\u0026#34;\rand o_orderkey = \u0026#34;line:l_orderkey\u0026#34;\rand o_orderstatus = \u0026#39;F\u0026#39;\rand \u0026#34;line:l_receiptdate\u0026#34; \u0026gt; \u0026#34;line:l_commitdate\u0026#34;\rand exists (\rselect * from\r\u0026#34;lambda:hbase\u0026#34;.default.lineitem\rwhere\r\u0026#34;line:l_orderkey\u0026#34; = \u0026#34;line:l_orderkey\u0026#34;\r)\rgroup by s_name\rorder by numwait desc,s_name; ShippedLineitemsPricingReport\nSELECT \u0026#34;line:l_returnflag\u0026#34;,\u0026#34;line:l_linestats\u0026#34;,\rsum(cast(\u0026#34;line:l_quantity\u0026#34; AS double)) AS sum_qty,\rsum(cast(\u0026#34;line:l_extendedprice\u0026#34; AS double)) AS sum_base_price,\rsum(cast(\u0026#34;line:l_extendedprice\u0026#34; AS double)*(1-cast(\u0026#34;line:l_discount\u0026#34; AS double))) AS sum_disc_price,\rsum(cast(\u0026#34;line:l_extendedprice\u0026#34; AS double)*(1-cast(\u0026#34;line:l_discount\u0026#34; AS double))*(1+cast(\u0026#34;line:l_tax\u0026#34; AS double))) AS sum_charge,\ravg(cast(\u0026#34;line:l_quantity\u0026#34; AS double)) AS avg_qty,\ravg(cast(\u0026#34;line:l_extendedprice\u0026#34; AS double)) AS avg_price,\ravg(cast(\u0026#34;line:l_discount\u0026#34; AS double)) AS avg_disc,\rcount(*) AS count_order\rFROM \u0026#34;lambda:hbase\u0026#34;.default.lineitem GROUP BY \u0026#34;line:l_returnflag\u0026#34;, \u0026#34;line:l_linestats\u0026#34;\rORDER BY \u0026#34;line:l_returnflag\u0026#34;, \u0026#34;line:l_linestats\u0026#34;; "
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]